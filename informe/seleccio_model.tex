\section{Selecció del model}
Una vegada d'han descrit i comentat els tres models per separat, cal ajuntar els resultats i escollir un dels models.

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
\textbf{Model} & \textbf{Cross Validation} & \textbf{Test} \\
\hline
KNN & 0.6287 & 0.7365 \\
DT & 0.8319 & 07097 \\
SVM & 0.7463 & 0.8139 \\
\hline
\end{tabular}
\caption{Mètrica \textit{f1-score-weighted} dels 3 models en cross validation i en test.}
\label{tab:models-val-test}
\end{table}

En la taula \ref{tab:models-val-test} es poden veure els resultats de \textit{f1-score-weighted} per els 3 models, tant en la validació com en el test. El model amb millor puntuació en el test és clarament la SVM, així que sembla que serà el model escollit per descriure més detalladament.

Com a observacions, es pot veure que en els tres datasets escollits pels models no s'eliminen outliers. És a dir, la eliminació d'outliers redueix el rendiment en aquests models. A més, en tots s'eliminen les mostres amb 9 NaNs. Això segurament és així degut a que la imputació de valors no és destacablement bona, de manera que és més efectiu eliminar les files amb molts missings i posteriorment aplicar algun mètode de balanceig (en aquests casos \textit{Oversampling} i \textit{SMOTE}) a partir de dades de major qualitat.

Per altres modificacions en el dataset, com ara l'escalat de variables o la codificació, només s'apliquen a dos dels tres models, de manera que no es pot dir de forma general que aplicar o no aquestes modificacions sigui millor pel rendiment general dels models predictius. No obstant, en la imputació de valors tots els models han escollit al Random Forest Classifier (amb mètode `gini') com el millor mètode per variables categòriques, de manera que es pot dir que és millor de forma general que els altres mètodes provats.

Amb tots els resultats observats, s'ha decidit que el model escollit per fer la Model Card i una descripció més detallada serà la SVM, degut a la seva puntuació en el test i a la seva poca tendència de predir la classe majoritària per sobre de les altres.

\subsection{Descripció del model triat}
En aquest model, s'utilitza un kernel lineal. Això significa que el model busca una frontera de decisió lineal en l'espai de característiques original. En altres paraules, intenta separar les classes utilitzant una línia, pla o hiperpla, depenent del nombre de característiques d'entrada.

El kernel lineal és particularment útil quan es treballa amb un gran nombre de variables degut a que tenen una menor tendència al sobreajustament (overfitting) en comparació als kernels no lineals. Això pot ser un dels motius pels que el model ha aconseguit resultats tan bons en el test.

El paràmetre C (en aquest model model, C = 5) controla el compromís entre classificar correctament tots els punts d'entrenament i tenir una frontera de decisió el més simple possible.

Un valor més alt de C significa que el model penalitza més els errors de classificació durant l'entrenament, conduint a una frontera de decisió que intenta classificar més correctament tots els punts d'entrenament, sovint a costa de generar overfitting. Per altra banda, un valor més baix de C dona més importància a la simplicitat de la frontera de decisió, la qual cosa pot millorar la generalització a costa de cometre més errors en el conjunt d'entrenament.

Finalment, el paràmetre gamma ja s'ha mencionat que no té influència en aquest cas, ja que només afecta a kernels no lineals.

En resum, aquest model SVM busca una frontera de decisió lineal que equilibra la classificació correcta dels punts d'entrenament amb la simplicitat de la frontera de decisió. El valor de C = 5 és més propens a overfitting que no pas el valor per defecte que proporciona \texttt{scikit-learn} (C = 1), motiu pel qual segurament ha obtingut millors resultats en la validació). No obstant, aquest overfitting es compensa pel fet de fer servir un kernel lineal, que generalment té menys tendència al sobreajustament.

\subsection{Anàlisi de les limitacions i capacitats del model}
Tal i com s'ha vist en la taula \ref{tab:svm-test} i en la figura \ref{fig:svm-cm}, aquest model té una bona \textit{accuracy} global (de 0,8) que indica que, en general, el model és capaç de classificar correctament un 80\% de les instàncies. Això es reafirma amb un score \textit{f1-score-weighted} de 0,8139 en el conjunt de test, el qual indica una bona harmonia entre la \textit{precision} i el \textit{recall} del model.

No obstant això, l'anàlisi detallada de la matriu de confusió mostra algunes limitacions del model:
\begin{itemize}
	\item \textbf{Confusions entre classes}: Observem que hi ha una mica de confusió entre la classe `Alive' i `Dead', amb 4 instàncies `Alive' que s'han classificat com a `Dead' i 1 instància `Dead' classificada com a `Alive'. Això pot ser indicatiu d'una frontera de decisió que no és totalment òptima entre aquestes dues classes. A més, també hi ha 3 instàncies de `Alive' i 2 de `Dead' classificades com a `LiverTransplant', indicant que hi ha una lleugera tendència a classificar `LiverTransplant' en casos on no s'hauria de fer.
	
	\item \textbf{Variància en els scores de validació i test}: La puntuació de la validació creuada (0,746) és lleugerament inferior al \textit{f1-score-weighted} obtinguts en el conjunt de test, suggerint que el model podria estar beneficiant-se d'alguna sort d'overfitting específic del conjunt de test o que el procés de validació creuada no captura completament la variabilitat del conjunt de dades. Per tant, en certs escenaris, potser el model no generalitzaria prou bé.

\end{itemize}

En resum, tot i que model té molt bones mètriques en general, té desperfectes a l'hora de realitzar la predicció, confonent algunes prediccions, especialment tendint a tenir més falsos positius en `LiverTransplant' i `Dead'. A més, és possible que hagi estat relativament afavorit pel factor aleatori.

\subsection{Resultats}
Els resultats del model SVM escollit ja s'han mencionat anteriorment. No obstant, per una major rigorositat de l'anàlisi, s'han realitzat 5 execucions amb exactament les mateixes condicions, datasets i paràmetres que anteriorment, però modificant la llavor aleatòria (concretament, s'han utilitzat les llavors: 29, 34, 85, 32, 5. La mitjana de \textit{f1-score-weighted} en aquests 5 experiments ha estat de 0,6398, considerablement més baixa que la que ha sortit en l'experiment anterior (amb la llavor 42). Per tant, aquest model no és tant bo com semblava, ja que el seu resultat varia bastant en funció de la llavor utilitzada.

Com ja s'ha dit anteriorment, els paràmetres dels models s'haurien d'escollir fent execucions amb múltiples llavors i amb la mitjana dels resultats. No obstant, en aquest estudi no s'ha fet degut a que s'ha considerat que l'enfoc més important es troba en l'anàlisi i no tant en el propi rendiment dels models. A més, amb una sola llavor la reproductibilitat és més fàcil, s'estalvien temps d'execució, fàcil comparació amb altres models i simplificació.

En el següent apartat d'aquest document es realitza una Model Card sobre el model escollit. Una vegada s'ha fet la reflexió de que realment el model escollit no és tant bo com semblava, per aquesta model card es tindran en consideració només els resultats amb la llavor 42, ja que fer una model card d'un model que no rendeix correctament és molt difícil (ja que s'estaria intentant justificar un model que no rendeix suficientment bé). Es vol reiterar que el propòsit d'aquest pràctica es centra en fer un bon anàlisi, i no pas un bon model. Per tant, es farà una model card justificant el rendiment del model com si, de forma general, fos igual de bo que l'obtingut amb la llavor 42. Evidentment, si aquest model s'hagués aplicar en la realitat i el propòsit d'aquest projecte no fos adquirir coneixement en Machine Learning i anàlisi de dades, es farien modificacions en el model i es faria la Model Card tenint en compte molts més resultats.
